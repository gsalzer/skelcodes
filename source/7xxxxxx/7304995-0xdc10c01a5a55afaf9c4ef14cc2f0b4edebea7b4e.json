{"status":"1","message":"OK","result":[{"SourceCode":"pragma solidity ^0.5.4;\r\npragma experimental ABIEncoderV2;\r\n\r\n\r\ncontract AI_on_BlockChain__BaseComponent {\r\n    \r\n\r\n    struct NeuralNetWork_Struct_Object\r\n    {\r\n        uint Im_Number_Of_Layer ;\r\n        uint[] Im_Nodes_In_EachLayer;\r\n        int[][] Im_Bias_Of_Nodes_In_EachLayer;\r\n        int[][][] Im_Weights_Of_Nodes_In_EachLayer;\r\n    }    \r\n    \r\n    function Im_StanderRandomNumber(uint _Im_Cute_Input_Number) \r\n    public view  \r\n    returns (int _Im_Random)\r\n    {\r\n        //Worship LuGoddess\r\n        require(msg.sender != block.coinbase);\r\n        require(msg.sender == tx.origin);\r\n        \r\n        int _Im_RandomNumber = (int(keccak256(abi.encodePacked(blockhash(block.number - 1), msg.sender, block.difficulty,  _Im_Cute_Input_Number))) % 2)  - 1;\r\n        \r\n        return _Im_RandomNumber;\r\n    }\r\n        \r\n    \r\n    function Im_Function_Initialize_NeuralNetwork(uint TotalNumber_Of_Layer, uint[] memory WeR_Nodes_In_EachLayer) \r\n    public view \r\n    returns (NeuralNetWork_Struct_Object memory Im_NeuralNetWork_Object)\r\n    {\r\n        \r\n        int[][] memory WeR_Bias_Of_Nodes_In_EachLayer;\r\n        int[][][] memory WeR_Weights_Of_Nodes_In_EachLayer;\r\n        \r\n        for (uint Im_Number_Of_Layer = 1 ; Im_Number_Of_Layer <= TotalNumber_Of_Layer ; Im_Number_Of_Layer++) \r\n        {\r\n            for(uint Im_Number_Of_Node = 0 ; Im_Number_Of_Node <= WeR_Nodes_In_EachLayer[Im_Number_Of_Layer]; Im_Number_Of_Node++) \r\n            {\r\n                WeR_Bias_Of_Nodes_In_EachLayer[Im_Number_Of_Layer][Im_Number_Of_Node] = Im_StanderRandomNumber(now)-1;\r\n                \r\n                for(uint Im_Weights_For_Node ;  Im_Weights_For_Node <= WeR_Nodes_In_EachLayer[Im_Number_Of_Layer-1] ; Im_Weights_For_Node++){\r\n                    \r\n                    WeR_Weights_Of_Nodes_In_EachLayer[Im_Number_Of_Layer][Im_Number_Of_Node][Im_Weights_For_Node]= Im_StanderRandomNumber(now);\r\n                }\r\n            }\r\n        }\r\n        \r\n        NeuralNetWork_Struct_Object memory Im_NeuralNetWork_Struct_Object = NeuralNetWork_Struct_Object\r\n        (\r\n            {Im_Number_Of_Layer : TotalNumber_Of_Layer,\r\n            Im_Nodes_In_EachLayer : WeR_Nodes_In_EachLayer,\r\n            Im_Bias_Of_Nodes_In_EachLayer : WeR_Bias_Of_Nodes_In_EachLayer,\r\n            Im_Weights_Of_Nodes_In_EachLayer : WeR_Weights_Of_Nodes_In_EachLayer}\r\n        );\r\n        \r\n        return Im_NeuralNetWork_Struct_Object;\r\n    }\r\n    \r\n    \r\n    \r\n    \r\n    function Im_Sum_For_NodeInput(int[] memory Im_InputData, int[] memory Im_EachWeights, int Im_Bias) \r\n    public pure \r\n    returns (int TransferValue_For_ActivationFunction) \r\n    {\r\n        int Sum_Value;\r\n        for(uint Im_Calculous_Pair = 0; Im_Calculous_Pair < Im_InputData.length; Im_Calculous_Pair++)\r\n        {\r\n            Sum_Value = Sum_Value + Im_InputData[Im_Calculous_Pair] * Im_EachWeights[Im_Calculous_Pair];\r\n        }\r\n        \r\n        Sum_Value = Sum_Value + Im_Bias;\r\n        \r\n        return Sum_Value;\r\n    }\r\n    \r\n}\r\n\r\n\r\ncontract AI_on_BlockChain__ComputationFunction is AI_on_BlockChain__BaseComponent{\r\n\r\n\r\n    \r\n    function Im_Activation_Function__Sigmoid(int Im_InputValue) \r\n    public pure \r\n    returns (int Im_OutputValue) \r\n    {\r\n        //int Im_interger = 12345e-2;\r\n        int Im_Exponencial_Number;\r\n        int Im_Sigmoid_Output;\r\n        \r\n//searching oprand        Im_Exponencial_Number = int(2.71828) ** (- Im_InputValue);\r\n        \r\n        Im_Sigmoid_Output = 1 / ( 1 + Im_Exponencial_Number );\r\n         \r\n        return  Im_Sigmoid_Output;\r\n        \r\n    }\r\n    \r\n    \r\n    \r\n    function Im_Activation_Function__Relu(int Im_Input) \r\n    public pure \r\n    returns (int Im_Output) \r\n    {\r\n        \r\n        int Im_Relu_Output;\r\n        \r\n        if(Im_Input <= 0)\r\n        {\r\n            Im_Relu_Output = 0;  \r\n        } \r\n        \r\n        \r\n        else if(Im_Input > 0)\r\n        {\r\n            Im_Relu_Output = Im_Input;\r\n        }\r\n        \r\n        return Im_Relu_Output;\r\n        \r\n    }\r\n\r\n\r\n    function Im_sigmoid_function_Derivative (int Im_InputValue)\r\n    public pure\r\n    returns(int Im_OutputValue) \r\n    {\r\n        int Im_OutputValue_Computation;\r\n        \r\n        Im_OutputValue_Computation = Im_InputValue * (1 - Im_InputValue);\r\n        \r\n        return Im_OutputValue_Computation;\r\n    }\r\n\r\n\r\n//    function Im_relu_function_Derivative () returns() {    }\r\n    \r\n    \r\n    function Im_Loss_function__L2 (int[] memory Im_Predict_ResultSets, int[] memory Im_Actual_ResultSets) \r\n    public pure\r\n    returns (int Im_Result_Error) \r\n    {\r\n        int Im_L2_Error;\r\n        \r\n        for (uint Im_Number_Of_ComputationalPair ; Im_Number_Of_ComputationalPair < Im_Predict_ResultSets.length; Im_Number_Of_ComputationalPair++)\r\n        {\r\n            int Im_Residual;\r\n            Im_Residual = Im_Actual_ResultSets[Im_Number_Of_ComputationalPair] - Im_Predict_ResultSets[Im_Number_Of_ComputationalPair];\r\n            Im_L2_Error = Im_L2_Error + (Im_Residual * Im_Residual);\r\n        }\r\n        \r\n        return Im_L2_Error;\r\n    }\r\n\r\n    function Im_Loss_function__MSE (int[] memory Im_Predict_ResultSets, int[] memory Im_Actual_ResultSets) \r\n    public pure \r\n    returns (int Im_Result_Error) \r\n    {\r\n        int Im_MSE_Error;\r\n        \r\n        for (uint Im_Number_Of_ComputationalPair ; Im_Number_Of_ComputationalPair < Im_Predict_ResultSets.length; Im_Number_Of_ComputationalPair++)\r\n        {\r\n            int Im_Residual;\r\n            Im_Residual = Im_Actual_ResultSets[Im_Number_Of_ComputationalPair] - Im_Predict_ResultSets[Im_Number_Of_ComputationalPair];\r\n            Im_MSE_Error = Im_MSE_Error + (Im_Residual * Im_Residual);\r\n        }        \r\n        Im_MSE_Error = Im_MSE_Error / int(Im_Predict_ResultSets.length);\r\n        \r\n        return Im_MSE_Error;\r\n    }\r\n}\r\n\r\ncontract AI_on_BlockChain__Operations is AI_on_BlockChain__ComputationFunction {\r\n    \r\n\r\n\r\n\r\n\r\n// throw out the input summation of each node and partial derivative of input summation respect to each weight\r\n\r\n    function Im_Backward_Propagation__ForwardPass(int[] memory Im_Current_InputData, NeuralNetWork_Struct_Object memory Im_NeuralNetWork_Object)\r\n    public pure\r\n    returns (int[][] memory InputSum_Of_Nodes, int[][][] memory Im_PartialDerivative__Of_InputSum_RespectTo_Weights)\r\n    {\r\n        int[][] memory Im_InputSum_Of_Nodes;\r\n        int[][][] memory Im_PartialDerivative_Of_InputSum_RespectTo_Weights;\r\n        \r\n        int[] memory Im_Current_FlowingTensor;\r\n        int[] memory Im_New_FlowingTensor;        \r\n        Im_Current_FlowingTensor = Im_Current_InputData;\r\n        \r\n        for(uint Im_Propagation_Layer = 1; Im_Propagation_Layer <= Im_NeuralNetWork_Object.Im_Number_Of_Layer; Im_Propagation_Layer++)\r\n        {\r\n            for(uint Im_Current_Neural = 0; Im_Current_Neural <= Im_NeuralNetWork_Object.Im_Nodes_In_EachLayer[Im_Propagation_Layer]; Im_Current_Neural++)\r\n            {\r\n                int Im_Activation_Function_Input_Sum;\r\n                Im_Activation_Function_Input_Sum = Im_Sum_For_NodeInput\r\n                (\r\n                    Im_Current_FlowingTensor, \r\n                    Im_NeuralNetWork_Object.Im_Weights_Of_Nodes_In_EachLayer[Im_Propagation_Layer][Im_Current_Neural], \r\n                    Im_NeuralNetWork_Object.Im_Bias_Of_Nodes_In_EachLayer[Im_Propagation_Layer][Im_Current_Neural]\r\n                );\r\n                \r\n                Im_New_FlowingTensor[Im_Current_Neural] = Im_Activation_Function__Sigmoid(Im_Activation_Function_Input_Sum);\r\n                \r\n//                \r\n                Im_InputSum_Of_Nodes[Im_Propagation_Layer][Im_Current_Neural] = Im_Activation_Function_Input_Sum;\r\n                Im_PartialDerivative_Of_InputSum_RespectTo_Weights[Im_Propagation_Layer][Im_Current_Neural] = Im_Current_FlowingTensor;\r\n//                \r\n            }\r\n            \r\n            Im_Current_FlowingTensor = Im_New_FlowingTensor;\r\n\r\n        }\r\n        \r\n        return (Im_InputSum_Of_Nodes, Im_PartialDerivative_Of_InputSum_RespectTo_Weights); \r\n        \r\n    }\r\n    \r\n\r\n    function Im_Backward_Propagation__BackwardPass(int[] memory Im_PartialDerivative__Current_Error, int[][] memory Im_InputSum_Of_Nodes, NeuralNetWork_Struct_Object memory Im_NeuralNetWork_Object)\r\n    public pure\r\n    returns (int[][] memory PartialDerivative__of_Error_RespectTo_InputSum_Of_Nodes)\r\n    {\r\n        \r\n        int[][] memory Im_PartialDerivative__of_Error_RespectTo_InputSum_Of_Nodes;\r\n        int[] memory Im_PartialDerivative__TensorSet___In_Previous_Layer;\r\n        \r\n        Im_PartialDerivative__TensorSet___In_Previous_Layer = Im_PartialDerivative__Current_Error;\r\n        \r\n        \r\n        for(uint Im_Propagation_Layer = 1; Im_Propagation_Layer <= Im_NeuralNetWork_Object.Im_Number_Of_Layer; Im_Propagation_Layer++)\r\n        {\r\n\r\n            int[] memory Im_PartialDerivative__InputSum_Of_Nodes___In_Current_Layer;            \r\n            \r\n            for(uint Im_Current_Neural = 0; Im_Current_Neural <= Im_NeuralNetWork_Object.Im_Nodes_In_EachLayer[Im_Propagation_Layer]; Im_Current_Neural++)\r\n            {\r\n                int Im_Sum_Of__Weight_Time_PartialDerivativePreviousLayerInputSum;\r\n                int Im_PartialDerivative__Current_Neural;\r\n                \r\n                for(uint Im_Number_Of_CurrentWeight; Im_Number_Of_CurrentWeight < Im_NeuralNetWork_Object.Im_Weights_Of_Nodes_In_EachLayer[Im_Propagation_Layer][Im_Current_Neural].length; Im_Number_Of_CurrentWeight++)\r\n                {\r\n                    int Im_CurrentWeight;\r\n                    int Im_PartialDerivative_PreviousLayerInputSum;\r\n                    \r\n                    Im_CurrentWeight = Im_NeuralNetWork_Object.Im_Weights_Of_Nodes_In_EachLayer[Im_Propagation_Layer][Im_Current_Neural][Im_Number_Of_CurrentWeight];\r\n                    Im_PartialDerivative_PreviousLayerInputSum = Im_PartialDerivative__TensorSet___In_Previous_Layer[Im_Number_Of_CurrentWeight];\r\n                    \r\n                    Im_Sum_Of__Weight_Time_PartialDerivativePreviousLayerInputSum = Im_Sum_Of__Weight_Time_PartialDerivativePreviousLayerInputSum + (Im_CurrentWeight * Im_PartialDerivative_PreviousLayerInputSum);\r\n                }\r\n                \r\n                Im_PartialDerivative__Current_Neural = Im_sigmoid_function_Derivative(Im_InputSum_Of_Nodes[Im_Propagation_Layer][Im_Current_Neural]) * Im_Sum_Of__Weight_Time_PartialDerivativePreviousLayerInputSum;\r\n                Im_PartialDerivative__InputSum_Of_Nodes___In_Current_Layer[Im_Current_Neural] = Im_PartialDerivative__Current_Neural;\r\n            }\r\n            \r\n            Im_PartialDerivative__of_Error_RespectTo_InputSum_Of_Nodes[Im_NeuralNetWork_Object.Im_Number_Of_Layer - Im_Propagation_Layer] = Im_PartialDerivative__InputSum_Of_Nodes___In_Current_Layer;\r\n            Im_PartialDerivative__TensorSet___In_Previous_Layer = Im_PartialDerivative__InputSum_Of_Nodes___In_Current_Layer;\r\n            \r\n        }\r\n        \r\n        return Im_PartialDerivative__of_Error_RespectTo_InputSum_Of_Nodes;\r\n        \r\n    }\r\n    \r\n    \r\n    \r\n}\r\n\r\n\r\ncontract AI_on_BlockChain__Excution is AI_on_BlockChain__Operations {\r\n    \r\n    function Im_Forward_Propagation__Prediction(int[] memory Im_Input_Feature , NeuralNetWork_Struct_Object memory Im_NeuralNetWork_Object)\r\n    public pure\r\n    returns(int Im_OutPut_PredictionResult)\r\n    {\r\n\r\n        int[] memory Im_Current_FlowingTensor;\r\n        int[] memory Im_New_FlowingTensor;\r\n        int Im_OutPutResult;\r\n        Im_Current_FlowingTensor = Im_Input_Feature;\r\n        \r\n        for(uint Im_Propagation_Layer = 1; Im_Propagation_Layer <= Im_NeuralNetWork_Object.Im_Number_Of_Layer; Im_Propagation_Layer++)\r\n        {\r\n            for(uint Im_Current_Neural = 0; Im_Current_Neural <= Im_NeuralNetWork_Object.Im_Nodes_In_EachLayer[Im_Propagation_Layer]; Im_Current_Neural++)\r\n            {\r\n                int Im_Activation_Function_Input_Sum;\r\n                Im_Activation_Function_Input_Sum = Im_Sum_For_NodeInput\r\n                (\r\n                    {Im_InputData : Im_Current_FlowingTensor, \r\n                    Im_EachWeights : Im_NeuralNetWork_Object.Im_Weights_Of_Nodes_In_EachLayer[Im_Propagation_Layer][Im_Current_Neural], \r\n                    Im_Bias : Im_NeuralNetWork_Object.Im_Bias_Of_Nodes_In_EachLayer[Im_Propagation_Layer][Im_Current_Neural]}\r\n                );\r\n                \r\n                Im_New_FlowingTensor[Im_Current_Neural] = Im_Activation_Function__Sigmoid(Im_Activation_Function_Input_Sum);\r\n            }\r\n            \r\n            Im_Current_FlowingTensor = Im_New_FlowingTensor;\r\n\r\n        }\r\n        \r\n        Im_OutPutResult = Im_Current_FlowingTensor[0];\r\n        \r\n        return Im_OutPutResult;\r\n    }    \r\n    \r\n\r\n\r\n\r\n    function Im_TrainingFunction_ByBackwardPropagation\r\n    (\r\n        int[][] memory Im_Input_Feature, \r\n        int[] memory Im_Input_Label, \r\n        int Learing_Rate, uint TrainingTimes, \r\n        NeuralNetWork_Struct_Object memory Im_NeuralNetWork_Object\r\n    )\r\n    public pure\r\n    returns (int Avrage_Error)\r\n    {\r\n        \r\n// initialize original weight equal to Im_NeuralNetWork_Object.Im_Weights_Of_Nodes_In_EachLayer\r\n        int[][][] memory Im_Current_WeightSet_Of_Nodes_In_EachLayer = Im_NeuralNetWork_Object.Im_Weights_Of_Nodes_In_EachLayer;\r\n\r\n    // loop training times\r\n        for(uint Im_NumberOfTraining = 0; Im_NumberOfTraining < TrainingTimes; Im_NumberOfTraining++ )\r\n        {\r\n\r\n            int[] memory Im_OutPut_PredictionResultSet;\r\n            int Im_Total_LossValue;            \r\n            \r\n            for(uint Im_NumberOfData; Im_NumberOfData < Im_Input_Label.length ; Im_NumberOfData)\r\n            {\r\n                int Im_OutPut_PredictionResult;\r\n            //    forward propogation compute all the prediction value for total input feature\r\n                Im_OutPut_PredictionResult = Im_Forward_Propagation__Prediction({Im_Input_Feature : Im_Input_Feature[Im_NumberOfData], Im_NeuralNetWork_Object : Im_NeuralNetWork_Object});\r\n                Im_OutPut_PredictionResultSet[Im_NumberOfData] = Im_OutPut_PredictionResult;\r\n            }\r\n            \r\n            //    compute the total loss of the current weight from all the prediction value and actual value(label\r\n            Im_Total_LossValue = Im_Total_LossValue + Im_Loss_function__L2({Im_Predict_ResultSets : Im_OutPut_PredictionResultSet, Im_Actual_ResultSets : Im_Input_Label});\r\n            \r\n            //    compute partial derivative of loss respect to weight\r\n            int[][] memory Im_InputSum_Of_EachNodes;\r\n            int[][][] memory Im_PartialDerivative__Of_InputSum_RespectTo_Weights;\r\n            int[][] memory Im_PartialDerivative__of_Error_RespectTo_InputSum_Of_Nodes;\r\n            \r\n//            (Im_InputSum_Of_EachNodes, Im_PartialDerivative__Of_InputSum_RespectTo_Weights) = Im_Backward_Propagation__ForwardPass( , );\r\n//            Im_PartialDerivative__of_Error_RespectTo_InputSum_Of_Nodes = Im_Backward_Propagation__BackwardPass();\r\n\r\n            \r\n            \r\n            //    update partial derivative of loss respect to weight by updateing : (weight = Learing_Rate * partial derivative of loss respect to weight)\r\n            \r\n            \r\n        \r\n        }\r\n        \r\n//        return  ;\r\n    }\r\n    \r\n//End of contract   \r\n}\r\n\r\n\r\n//Update by meowent@gmail.com\r\n//worship LuGoddess","ABI":"[{\"constant\":true,\"inputs\":[{\"name\":\"TotalNumber_Of_Layer\",\"type\":\"uint256\"},{\"name\":\"WeR_Nodes_In_EachLayer\",\"type\":\"uint256[]\"}],\"name\":\"Im_Function_Initialize_NeuralNetwork\",\"outputs\":[{\"components\":[{\"name\":\"Im_Number_Of_Layer\",\"type\":\"uint256\"},{\"name\":\"Im_Nodes_In_EachLayer\",\"type\":\"uint256[]\"},{\"name\":\"Im_Bias_Of_Nodes_In_EachLayer\",\"type\":\"int256[][]\"},{\"name\":\"Im_Weights_Of_Nodes_In_EachLayer\",\"type\":\"int256[][][]\"}],\"name\":\"Im_NeuralNetWork_Object\",\"type\":\"tuple\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"Im_InputValue\",\"type\":\"int256\"}],\"name\":\"Im_Activation_Function__Sigmoid\",\"outputs\":[{\"name\":\"Im_OutputValue\",\"type\":\"int256\"}],\"payable\":false,\"stateMutability\":\"pure\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"Im_InputValue\",\"type\":\"int256\"}],\"name\":\"Im_sigmoid_function_Derivative\",\"outputs\":[{\"name\":\"Im_OutputValue\",\"type\":\"int256\"}],\"payable\":false,\"stateMutability\":\"pure\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"Im_PartialDerivative__Current_Error\",\"type\":\"int256[]\"},{\"name\":\"Im_InputSum_Of_Nodes\",\"type\":\"int256[][]\"},{\"components\":[{\"name\":\"Im_Number_Of_Layer\",\"type\":\"uint256\"},{\"name\":\"Im_Nodes_In_EachLayer\",\"type\":\"uint256[]\"},{\"name\":\"Im_Bias_Of_Nodes_In_EachLayer\",\"type\":\"int256[][]\"},{\"name\":\"Im_Weights_Of_Nodes_In_EachLayer\",\"type\":\"int256[][][]\"}],\"name\":\"Im_NeuralNetWork_Object\",\"type\":\"tuple\"}],\"name\":\"Im_Backward_Propagation__BackwardPass\",\"outputs\":[{\"name\":\"PartialDerivative__of_Error_RespectTo_InputSum_Of_Nodes\",\"type\":\"int256[][]\"}],\"payable\":false,\"stateMutability\":\"pure\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"Im_Input_Feature\",\"type\":\"int256[]\"},{\"components\":[{\"name\":\"Im_Number_Of_Layer\",\"type\":\"uint256\"},{\"name\":\"Im_Nodes_In_EachLayer\",\"type\":\"uint256[]\"},{\"name\":\"Im_Bias_Of_Nodes_In_EachLayer\",\"type\":\"int256[][]\"},{\"name\":\"Im_Weights_Of_Nodes_In_EachLayer\",\"type\":\"int256[][][]\"}],\"name\":\"Im_NeuralNetWork_Object\",\"type\":\"tuple\"}],\"name\":\"Im_Forward_Propagation__Prediction\",\"outputs\":[{\"name\":\"Im_OutPut_PredictionResult\",\"type\":\"int256\"}],\"payable\":false,\"stateMutability\":\"pure\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"Im_Predict_ResultSets\",\"type\":\"int256[]\"},{\"name\":\"Im_Actual_ResultSets\",\"type\":\"int256[]\"}],\"name\":\"Im_Loss_function__L2\",\"outputs\":[{\"name\":\"Im_Result_Error\",\"type\":\"int256\"}],\"payable\":false,\"stateMutability\":\"pure\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"_Im_Cute_Input_Number\",\"type\":\"uint256\"}],\"name\":\"Im_StanderRandomNumber\",\"outputs\":[{\"name\":\"_Im_Random\",\"type\":\"int256\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"Im_InputData\",\"type\":\"int256[]\"},{\"name\":\"Im_EachWeights\",\"type\":\"int256[]\"},{\"name\":\"Im_Bias\",\"type\":\"int256\"}],\"name\":\"Im_Sum_For_NodeInput\",\"outputs\":[{\"name\":\"TransferValue_For_ActivationFunction\",\"type\":\"int256\"}],\"payable\":false,\"stateMutability\":\"pure\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"Im_Input_Feature\",\"type\":\"int256[][]\"},{\"name\":\"Im_Input_Label\",\"type\":\"int256[]\"},{\"name\":\"Learing_Rate\",\"type\":\"int256\"},{\"name\":\"TrainingTimes\",\"type\":\"uint256\"},{\"components\":[{\"name\":\"Im_Number_Of_Layer\",\"type\":\"uint256\"},{\"name\":\"Im_Nodes_In_EachLayer\",\"type\":\"uint256[]\"},{\"name\":\"Im_Bias_Of_Nodes_In_EachLayer\",\"type\":\"int256[][]\"},{\"name\":\"Im_Weights_Of_Nodes_In_EachLayer\",\"type\":\"int256[][][]\"}],\"name\":\"Im_NeuralNetWork_Object\",\"type\":\"tuple\"}],\"name\":\"Im_TrainingFunction_ByBackwardPropagation\",\"outputs\":[{\"name\":\"Avrage_Error\",\"type\":\"int256\"}],\"payable\":false,\"stateMutability\":\"pure\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"Im_Predict_ResultSets\",\"type\":\"int256[]\"},{\"name\":\"Im_Actual_ResultSets\",\"type\":\"int256[]\"}],\"name\":\"Im_Loss_function__MSE\",\"outputs\":[{\"name\":\"Im_Result_Error\",\"type\":\"int256\"}],\"payable\":false,\"stateMutability\":\"pure\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"Im_Input\",\"type\":\"int256\"}],\"name\":\"Im_Activation_Function__Relu\",\"outputs\":[{\"name\":\"Im_Output\",\"type\":\"int256\"}],\"payable\":false,\"stateMutability\":\"pure\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"Im_Current_InputData\",\"type\":\"int256[]\"},{\"components\":[{\"name\":\"Im_Number_Of_Layer\",\"type\":\"uint256\"},{\"name\":\"Im_Nodes_In_EachLayer\",\"type\":\"uint256[]\"},{\"name\":\"Im_Bias_Of_Nodes_In_EachLayer\",\"type\":\"int256[][]\"},{\"name\":\"Im_Weights_Of_Nodes_In_EachLayer\",\"type\":\"int256[][][]\"}],\"name\":\"Im_NeuralNetWork_Object\",\"type\":\"tuple\"}],\"name\":\"Im_Backward_Propagation__ForwardPass\",\"outputs\":[{\"name\":\"InputSum_Of_Nodes\",\"type\":\"int256[][]\"},{\"name\":\"Im_PartialDerivative__Of_InputSum_RespectTo_Weights\",\"type\":\"int256[][][]\"}],\"payable\":false,\"stateMutability\":\"pure\",\"type\":\"function\"}]","ContractName":"AI_on_BlockChain__Excution","CompilerVersion":"v0.5.4+commit.9549d8ff","OptimizationUsed":"1","Runs":"200","ConstructorArguments":"","Library":"","SwarmSource":"bzzr://8a9f5e981119bfab6f136902230c3e08e4b501c42dd2558970686137a555264a"}]}